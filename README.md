# master-thesis-project-vioce-cloning
In this project, I provide the code for X-vector encoder, D-vector encoder and AdaIN-VC encoder. These encoder can extract 128-dimensional effective speaekr embeddings which is used in speaker adapation method. For each encoder, I provid the 100 samples of speaker embedding from 10 speakers. 

The pretrained models for each encoder and the trained TTS models of FastSpeech2 and Tacotron 2 for mandarin are provided in this link https://drive.google.com/drive/folders/1cy7G_g4wEr9Pe3OL69mx5G2kyt3N-AJH?usp=sharing. 

I submit the code for visualization the speaker embeddings. This code first reduces the dimension of the speaker embeddings and uses TSNE tool to visualize them.

I submit the samples of synthesized speech using three methods.
